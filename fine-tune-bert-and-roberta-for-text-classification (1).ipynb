{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom transformers import TFAutoModel, AutoTokenizer\nfrom datasets import load_dataset","metadata":{"execution":{"iopub.status.busy":"2023-10-27T03:10:14.908854Z","iopub.execute_input":"2023-10-27T03:10:14.909452Z","iopub.status.idle":"2023-10-27T03:10:14.916681Z","shell.execute_reply.started":"2023-10-27T03:10:14.909397Z","shell.execute_reply":"2023-10-27T03:10:14.915425Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"model = TFAutoModel.from_pretrained(\"bert-base-uncased\")","metadata":{"execution":{"iopub.status.busy":"2023-10-27T03:10:14.919192Z","iopub.execute_input":"2023-10-27T03:10:14.919948Z","iopub.status.idle":"2023-10-27T03:10:16.948594Z","shell.execute_reply.started":"2023-10-27T03:10:14.919900Z","shell.execute_reply":"2023-10-27T03:10:16.947396Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stderr","text":"Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nAll the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")","metadata":{"execution":{"iopub.status.busy":"2023-10-27T03:10:16.951438Z","iopub.execute_input":"2023-10-27T03:10:16.952240Z","iopub.status.idle":"2023-10-27T03:10:17.929764Z","shell.execute_reply.started":"2023-10-27T03:10:16.952193Z","shell.execute_reply":"2023-10-27T03:10:17.928715Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"inputs = tokenizer(['Hello world', 'Hi how are you'], padding=True, truncation=True,\n                  return_tensors='tf')\ninputs","metadata":{"execution":{"iopub.status.busy":"2023-10-27T03:10:17.932780Z","iopub.execute_input":"2023-10-27T03:10:17.933134Z","iopub.status.idle":"2023-10-27T03:10:17.943578Z","shell.execute_reply.started":"2023-10-27T03:10:17.933101Z","shell.execute_reply":"2023-10-27T03:10:17.942375Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"{'input_ids': <tf.Tensor: shape=(2, 6), dtype=int32, numpy=\narray([[ 101, 7592, 2088,  102,    0,    0],\n       [ 101, 7632, 2129, 2024, 2017,  102]], dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(2, 6), dtype=int32, numpy=\narray([[0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(2, 6), dtype=int32, numpy=\narray([[1, 1, 1, 1, 0, 0],\n       [1, 1, 1, 1, 1, 1]], dtype=int32)>}"},"metadata":{}}]},{"cell_type":"code","source":"output = model(inputs)\noutput","metadata":{"execution":{"iopub.status.busy":"2023-10-27T03:10:17.945059Z","iopub.execute_input":"2023-10-27T03:10:17.945448Z","iopub.status.idle":"2023-10-27T03:10:18.087519Z","shell.execute_reply.started":"2023-10-27T03:10:17.945415Z","shell.execute_reply":"2023-10-27T03:10:18.086252Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"TFBaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=<tf.Tensor: shape=(2, 6, 768), dtype=float32, numpy=\narray([[[-0.16888332,  0.13606355, -0.13940018, ..., -0.6251125 ,\n          0.05217262,  0.36714536],\n        [-0.3632745 ,  0.14121903,  0.8799885 , ...,  0.10433032,\n          0.2887578 ,  0.37267894],\n        [-0.69859415, -0.69879794,  0.06450251, ..., -0.22103661,\n          0.00986893, -0.5939796 ],\n        [ 0.83098257,  0.12366717, -0.15119013, ...,  0.10309545,\n         -0.67792666, -0.26285172],\n        [-0.40266633, -0.01928236,  0.5732502 , ..., -0.20656842,\n          0.02338582,  0.20126349],\n        [-0.6228408 , -0.27453488,  0.1811763 , ..., -0.12944865,\n         -0.03839079, -0.05733156]],\n\n       [[ 0.09286558, -0.02636361, -0.12239343, ..., -0.21063566,\n          0.17386371,  0.17250973],\n        [ 0.40742022, -0.05930945,  0.55234593, ..., -0.6790563 ,\n          0.6555748 , -0.2945646 ],\n        [-0.21155298, -0.6858643 , -0.46280792, ...,  0.15278494,\n          0.59774226, -0.9102001 ],\n        [ 0.3992125 , -1.3207804 , -0.08008753, ..., -0.32125378,\n          0.25572804, -0.57804394],\n        [-0.07565154, -1.3393834 ,  0.18162948, ...,  0.07461128,\n          0.40318406, -0.7079987 ],\n        [ 0.5988934 , -0.28409335, -0.34899247, ...,  0.30420092,\n         -0.4367556 , -0.20969652]]], dtype=float32)>, pooler_output=<tf.Tensor: shape=(2, 768), dtype=float32, numpy=\narray([[-0.90615326, -0.31115308, -0.6216535 , ..., -0.30575195,\n        -0.64009386,  0.91661745],\n       [-0.930967  , -0.3380703 , -0.62161595, ..., -0.44018963,\n        -0.68128854,  0.9348898 ]], dtype=float32)>, past_key_values=None, hidden_states=None, attentions=None, cross_attentions=None)"},"metadata":{}}]},{"cell_type":"code","source":"emotions = load_dataset('SetFit/emotion')","metadata":{"execution":{"iopub.status.busy":"2023-10-27T03:10:18.089047Z","iopub.execute_input":"2023-10-27T03:10:18.089404Z","iopub.status.idle":"2023-10-27T03:10:18.506285Z","shell.execute_reply.started":"2023-10-27T03:10:18.089371Z","shell.execute_reply":"2023-10-27T03:10:18.505241Z"},"trusted":true},"execution_count":39,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"575e9e8ccd544499a8f3a12f840c1071"}},"metadata":{}}]},{"cell_type":"code","source":"emotions","metadata":{"execution":{"iopub.status.busy":"2023-10-27T03:10:18.507613Z","iopub.execute_input":"2023-10-27T03:10:18.508017Z","iopub.status.idle":"2023-10-27T03:10:18.515262Z","shell.execute_reply.started":"2023-10-27T03:10:18.507984Z","shell.execute_reply":"2023-10-27T03:10:18.514020Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'label', 'label_text'],\n        num_rows: 16000\n    })\n    test: Dataset({\n        features: ['text', 'label', 'label_text'],\n        num_rows: 2000\n    })\n    validation: Dataset({\n        features: ['text', 'label', 'label_text'],\n        num_rows: 2000\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"def tokenize(batch):\n    return tokenizer(batch[\"text\"], padding=True, truncation=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-27T03:10:18.516574Z","iopub.execute_input":"2023-10-27T03:10:18.516932Z","iopub.status.idle":"2023-10-27T03:10:18.526904Z","shell.execute_reply.started":"2023-10-27T03:10:18.516901Z","shell.execute_reply":"2023-10-27T03:10:18.525578Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"emotions_encoded = emotions.map(tokenize, batched=True, batch_size=None)","metadata":{"execution":{"iopub.status.busy":"2023-10-27T03:10:18.528224Z","iopub.execute_input":"2023-10-27T03:10:18.528522Z","iopub.status.idle":"2023-10-27T03:10:21.523719Z","shell.execute_reply.started":"2023-10-27T03:10:18.528493Z","shell.execute_reply":"2023-10-27T03:10:21.522571Z"},"trusted":true},"execution_count":42,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc2fc1803a1a4da5b0c153b687d66579"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d7152de8e904956a5e225a14cf63ec0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4b1c3f51e16494f8b04cb248fea9482"}},"metadata":{}}]},{"cell_type":"code","source":"emotions_encoded","metadata":{"execution":{"iopub.status.busy":"2023-10-27T03:10:21.530442Z","iopub.execute_input":"2023-10-27T03:10:21.530836Z","iopub.status.idle":"2023-10-27T03:10:21.538247Z","shell.execute_reply.started":"2023-10-27T03:10:21.530799Z","shell.execute_reply":"2023-10-27T03:10:21.537084Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'label', 'label_text', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 16000\n    })\n    test: Dataset({\n        features: ['text', 'label', 'label_text', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 2000\n    })\n    validation: Dataset({\n        features: ['text', 'label', 'label_text', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 2000\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"# setting 'input_ids', 'attention_mask', 'token_type_ids', and 'label'\n# to the tensorflow format. Now if you access this dataset you will get these\n# columns in `tf.Tensor` format\n\nemotions_encoded.set_format('tf', \n                            columns=['input_ids', 'attention_mask', 'token_type_ids', 'label'])\n\n# setting BATCH_SIZE to 64.\nBATCH_SIZE = 64\n\ndef order(inp):\n    '''\n    This function will group all the inputs of BERT\n    into a single dictionary and then output it with\n    labels.\n    '''\n    data = list(inp.values())\n    return {\n        'input_ids': data[1],\n        'attention_mask': data[2],\n        'token_type_ids': data[3]\n    }, data[0]\n\n# converting train split of `emotions_encoded` to tensorflow format\ntrain_dataset = tf.data.Dataset.from_tensor_slices(emotions_encoded['train'][:])\n# set batch_size and shuffle\ntrain_dataset = train_dataset.batch(BATCH_SIZE).shuffle(1000)\n# map the `order` function\ntrain_dataset = train_dataset.map(order, num_parallel_calls=tf.data.AUTOTUNE)\n\n# ... doing the same for test set ...\ntest_dataset = tf.data.Dataset.from_tensor_slices(emotions_encoded['test'][:])\ntest_dataset = test_dataset.batch(BATCH_SIZE)\ntest_dataset = test_dataset.map(order, num_parallel_calls=tf.data.AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2023-10-27T03:10:21.539836Z","iopub.execute_input":"2023-10-27T03:10:21.540267Z","iopub.status.idle":"2023-10-27T03:10:22.154897Z","shell.execute_reply.started":"2023-10-27T03:10:21.540224Z","shell.execute_reply":"2023-10-27T03:10:22.153615Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"inp, out = next(iter(train_dataset)) # a batch from train_dataset\nprint(inp, '\\n\\n', out)","metadata":{"execution":{"iopub.status.busy":"2023-10-27T03:10:22.156658Z","iopub.execute_input":"2023-10-27T03:10:22.157124Z","iopub.status.idle":"2023-10-27T03:10:22.239585Z","shell.execute_reply.started":"2023-10-27T03:10:22.157078Z","shell.execute_reply":"2023-10-27T03:10:22.238452Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"{'input_ids': <tf.Tensor: shape=(64, 87), dtype=int64, numpy=\narray([[ 101, 1045, 2066, ...,    0,    0,    0],\n       [ 101, 1045, 2514, ...,    0,    0,    0],\n       [ 101, 1045, 2123, ...,    0,    0,    0],\n       ...,\n       [ 101, 1045, 2064, ...,    0,    0,    0],\n       [ 101, 1045, 2123, ...,    0,    0,    0],\n       [ 101, 1045, 2514, ...,    0,    0,    0]])>, 'attention_mask': <tf.Tensor: shape=(64, 87), dtype=int64, numpy=\narray([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       ...,\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0]])>, 'token_type_ids': <tf.Tensor: shape=(64, 87), dtype=int64, numpy=\narray([[1, 1, 1, ..., 0, 0, 0],\n       [1, 1, 1, ..., 0, 0, 0],\n       [1, 1, 1, ..., 0, 0, 0],\n       ...,\n       [1, 1, 1, ..., 0, 0, 0],\n       [1, 1, 1, ..., 0, 0, 0],\n       [1, 1, 1, ..., 0, 0, 0]])>} \n\n tf.Tensor(\n[3 2 2 1 0 0 3 1 1 4 1 1 0 0 2 1 1 1 1 1 0 1 2 1 4 1 0 1 1 4 1 0 4 1 0 1 0\n 4 1 1 4 0 0 1 1 1 1 4 1 1 4 1 4 5 1 4 5 4 1 1 5 0 0 1], shape=(64,), dtype=int64)\n","output_type":"stream"}]},{"cell_type":"code","source":"class BERTForClassification(tf.keras.Model):\n    \n    def __init__(self, bert_model, num_classes):\n        super().__init__()\n        self.bert = bert_model\n        self.fc = tf.keras.layers.Dense(num_classes, activation='softmax')\n        \n    def call(self, inputs):\n        x = self.bert(inputs)[1]\n        return self.fc(x)","metadata":{"execution":{"iopub.status.busy":"2023-10-27T03:10:22.240911Z","iopub.execute_input":"2023-10-27T03:10:22.241250Z","iopub.status.idle":"2023-10-27T03:10:22.248786Z","shell.execute_reply.started":"2023-10-27T03:10:22.241217Z","shell.execute_reply":"2023-10-27T03:10:22.247523Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"classifier = BERTForClassification(model, num_classes=6)\n\nclassifier.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n    metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-27T03:10:22.250556Z","iopub.execute_input":"2023-10-27T03:10:22.250935Z","iopub.status.idle":"2023-10-27T03:10:22.274038Z","shell.execute_reply.started":"2023-10-27T03:10:22.250903Z","shell.execute_reply":"2023-10-27T03:10:22.272820Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"history = classifier.fit(\n    train_dataset,\n    epochs=3\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-27T03:10:22.278188Z","iopub.execute_input":"2023-10-27T03:10:22.278533Z","iopub.status.idle":"2023-10-27T03:18:23.426932Z","shell.execute_reply.started":"2023-10-27T03:10:22.278499Z","shell.execute_reply":"2023-10-27T03:18:23.425769Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"Epoch 1/3\n250/250 [==============================] - 172s 616ms/step - loss: 1.0877 - accuracy: 0.5898\nEpoch 2/3\n250/250 [==============================] - 154s 617ms/step - loss: 0.2641 - accuracy: 0.9032\nEpoch 3/3\n250/250 [==============================] - 154s 617ms/step - loss: 0.1523 - accuracy: 0.9356\n","output_type":"stream"}]},{"cell_type":"code","source":"classifier.evaluate(test_dataset)","metadata":{"execution":{"iopub.status.busy":"2023-10-27T03:18:23.428530Z","iopub.execute_input":"2023-10-27T03:18:23.428915Z","iopub.status.idle":"2023-10-27T03:18:32.198184Z","shell.execute_reply.started":"2023-10-27T03:18:23.428881Z","shell.execute_reply":"2023-10-27T03:18:32.197004Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"32/32 [==============================] - 9s 168ms/step - loss: 0.1807 - accuracy: 0.9215\n","output_type":"stream"},{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"[0.18074743449687958, 0.921500027179718]"},"metadata":{}}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom transformers import TFAutoModel, AutoTokenizer\nfrom datasets import load_dataset","metadata":{"execution":{"iopub.status.busy":"2023-10-27T03:22:27.459194Z","iopub.execute_input":"2023-10-27T03:22:27.459939Z","iopub.status.idle":"2023-10-27T03:22:27.465329Z","shell.execute_reply.started":"2023-10-27T03:22:27.459900Z","shell.execute_reply":"2023-10-27T03:22:27.464107Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"model = TFAutoModel.from_pretrained(\"roberta-base\")","metadata":{"execution":{"iopub.status.busy":"2023-10-27T03:22:27.474114Z","iopub.execute_input":"2023-10-27T03:22:27.474578Z","iopub.status.idle":"2023-10-27T03:22:29.003647Z","shell.execute_reply.started":"2023-10-27T03:22:27.474540Z","shell.execute_reply":"2023-10-27T03:22:29.002557Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stderr","text":"Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nAll the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")","metadata":{"execution":{"iopub.status.busy":"2023-10-27T03:22:29.005893Z","iopub.execute_input":"2023-10-27T03:22:29.006204Z","iopub.status.idle":"2023-10-27T03:22:30.166039Z","shell.execute_reply.started":"2023-10-27T03:22:29.006174Z","shell.execute_reply":"2023-10-27T03:22:30.164936Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"inputs = tokenizer(['Hello world', 'Hi how are you'], padding=True, truncation=True,\n                  return_tensors='tf')\ninputs","metadata":{"execution":{"iopub.status.busy":"2023-10-27T03:22:30.168014Z","iopub.execute_input":"2023-10-27T03:22:30.168358Z","iopub.status.idle":"2023-10-27T03:22:30.177608Z","shell.execute_reply.started":"2023-10-27T03:22:30.168325Z","shell.execute_reply":"2023-10-27T03:22:30.176603Z"},"trusted":true},"execution_count":68,"outputs":[{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"{'input_ids': <tf.Tensor: shape=(2, 6), dtype=int32, numpy=\narray([[    0, 31414,   232,     2,     1,     1],\n       [    0, 30086,   141,    32,    47,     2]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(2, 6), dtype=int32, numpy=\narray([[1, 1, 1, 1, 0, 0],\n       [1, 1, 1, 1, 1, 1]], dtype=int32)>}"},"metadata":{}}]},{"cell_type":"code","source":"output = model(inputs)\noutput\n","metadata":{"execution":{"iopub.status.busy":"2023-10-27T03:22:30.178953Z","iopub.execute_input":"2023-10-27T03:22:30.179246Z","iopub.status.idle":"2023-10-27T03:22:30.317338Z","shell.execute_reply.started":"2023-10-27T03:22:30.179220Z","shell.execute_reply":"2023-10-27T03:22:30.316247Z"},"trusted":true},"execution_count":69,"outputs":[{"execution_count":69,"output_type":"execute_result","data":{"text/plain":"TFBaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=<tf.Tensor: shape=(2, 6, 768), dtype=float32, numpy=\narray([[[-0.06132455,  0.08516992,  0.00078   , ..., -0.06125636,\n         -0.05824584, -0.00582781],\n        [-0.1364578 , -0.01367003,  0.06624176, ...,  0.03447215,\n         -0.08437751,  0.14693369],\n        [-0.14509705,  0.17469448,  0.1423138 , ..., -0.48851636,\n         -0.19828328,  0.4867814 ],\n        [-0.06250261,  0.08806741, -0.020095  , ..., -0.11117796,\n         -0.06778044, -0.0407331 ],\n        [-0.09004237,  0.01524699,  0.11763413, ..., -0.01570032,\n         -0.08172794,  0.10898153],\n        [-0.09004237,  0.01524699,  0.11763413, ..., -0.01570032,\n         -0.08172794,  0.10898153]],\n\n       [[-0.05453827,  0.10439846, -0.00956053, ..., -0.06943446,\n         -0.04845492, -0.00215347],\n        [-0.10498375,  0.1532619 ,  0.09994312, ..., -0.32217735,\n          0.10816762, -0.06135899],\n        [-0.19492397,  0.11645846,  0.09339952, ..., -0.29414424,\n          0.11492234,  0.10838041],\n        [ 0.1924372 ,  0.6660279 , -0.0248056 , ..., -0.21616416,\n          0.29153123,  0.40086433],\n        [-0.10869795,  0.27551606,  0.16348495, ..., -0.033169  ,\n          0.1320385 ,  0.08477786],\n        [-0.04219619,  0.11705509, -0.02821404, ..., -0.12019771,\n         -0.05269971, -0.0277282 ]]], dtype=float32)>, pooler_output=<tf.Tensor: shape=(2, 768), dtype=float32, numpy=\narray([[ 0.01722784, -0.22285335, -0.21848685, ..., -0.13234457,\n        -0.04166932, -0.10243436],\n       [ 0.01543027, -0.21890427, -0.21031885, ..., -0.13072492,\n        -0.04849378, -0.11933702]], dtype=float32)>, past_key_values=None, hidden_states=None, attentions=None, cross_attentions=None)"},"metadata":{}}]},{"cell_type":"code","source":"emotions = load_dataset('SetFit/emotion')\n","metadata":{"execution":{"iopub.status.busy":"2023-10-27T03:22:30.321563Z","iopub.execute_input":"2023-10-27T03:22:30.322356Z","iopub.status.idle":"2023-10-27T03:22:31.336560Z","shell.execute_reply.started":"2023-10-27T03:22:30.322307Z","shell.execute_reply":"2023-10-27T03:22:31.335455Z"},"trusted":true},"execution_count":70,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a4ac1c317874ccb9f71dda11c7f9d6c"}},"metadata":{}}]},{"cell_type":"code","source":"emotions","metadata":{"execution":{"iopub.status.busy":"2023-10-27T03:22:31.337898Z","iopub.execute_input":"2023-10-27T03:22:31.338217Z","iopub.status.idle":"2023-10-27T03:22:31.345227Z","shell.execute_reply.started":"2023-10-27T03:22:31.338185Z","shell.execute_reply":"2023-10-27T03:22:31.344172Z"},"trusted":true},"execution_count":71,"outputs":[{"execution_count":71,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'label', 'label_text'],\n        num_rows: 16000\n    })\n    test: Dataset({\n        features: ['text', 'label', 'label_text'],\n        num_rows: 2000\n    })\n    validation: Dataset({\n        features: ['text', 'label', 'label_text'],\n        num_rows: 2000\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"def tokenize(batch):\n    return tokenizer(batch[\"text\"], padding=True, truncation=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-27T03:22:31.346594Z","iopub.execute_input":"2023-10-27T03:22:31.346960Z","iopub.status.idle":"2023-10-27T03:22:31.358917Z","shell.execute_reply.started":"2023-10-27T03:22:31.346928Z","shell.execute_reply":"2023-10-27T03:22:31.357802Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"emotions_encoded = emotions.map(tokenize, batched=True, batch_size=None)","metadata":{"execution":{"iopub.status.busy":"2023-10-27T03:22:31.360480Z","iopub.execute_input":"2023-10-27T03:22:31.361216Z","iopub.status.idle":"2023-10-27T03:22:34.542066Z","shell.execute_reply.started":"2023-10-27T03:22:31.361173Z","shell.execute_reply":"2023-10-27T03:22:34.540724Z"},"trusted":true},"execution_count":73,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9f3b5050e1e4702a7ce2316efa30714"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92ebc9b438964137902319553f07e169"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d33d3f4165384aa49c115f0bef90f4f9"}},"metadata":{}}]},{"cell_type":"code","source":"emotions_encoded","metadata":{"execution":{"iopub.status.busy":"2023-10-27T03:22:34.544076Z","iopub.execute_input":"2023-10-27T03:22:34.544503Z","iopub.status.idle":"2023-10-27T03:22:34.551869Z","shell.execute_reply.started":"2023-10-27T03:22:34.544453Z","shell.execute_reply":"2023-10-27T03:22:34.550710Z"},"trusted":true},"execution_count":74,"outputs":[{"execution_count":74,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'label', 'label_text', 'input_ids', 'attention_mask'],\n        num_rows: 16000\n    })\n    test: Dataset({\n        features: ['text', 'label', 'label_text', 'input_ids', 'attention_mask'],\n        num_rows: 2000\n    })\n    validation: Dataset({\n        features: ['text', 'label', 'label_text', 'input_ids', 'attention_mask'],\n        num_rows: 2000\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"# setting 'input_ids', 'attention_mask', 'token_type_ids', and 'label'\n# to the tensorflow format. Now if you access this dataset you will get these\n# columns in `tf.Tensor` format\n\nemotions_encoded.set_format('tf', \n                            columns=['input_ids', 'attention_mask', 'label'])\n\n# setting BATCH_SIZE to 64.\nBATCH_SIZE = 64\n\ndef order(inp):\n    '''\n    This function will group all the inputs of BERT\n    into a single dictionary and then output it with\n    labels.\n    '''\n    data = list(inp.values())\n    return {\n        'input_ids': data[1],\n        'attention_mask': data[2],\n#         'token_type_ids': data[3]\n    }, data[0]\n\n# converting train split of `emotions_encoded` to tensorflow format\ntrain_dataset = tf.data.Dataset.from_tensor_slices(emotions_encoded['train'][:])\n# set batch_size and shuffle\ntrain_dataset = train_dataset.batch(BATCH_SIZE).shuffle(1000)\n# map the `order` function\ntrain_dataset = train_dataset.map(order, num_parallel_calls=tf.data.AUTOTUNE)\n\n# ... doing the same for test set ...\ntest_dataset = tf.data.Dataset.from_tensor_slices(emotions_encoded['test'][:])\ntest_dataset = test_dataset.batch(BATCH_SIZE)\ntest_dataset = test_dataset.map(order, num_parallel_calls=tf.data.AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2023-10-27T03:22:34.553438Z","iopub.execute_input":"2023-10-27T03:22:34.554245Z","iopub.status.idle":"2023-10-27T03:22:34.982677Z","shell.execute_reply.started":"2023-10-27T03:22:34.554197Z","shell.execute_reply":"2023-10-27T03:22:34.981751Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"inp, out = next(iter(train_dataset)) # a batch from train_dataset\nprint(inp, '\\n\\n', out)","metadata":{"execution":{"iopub.status.busy":"2023-10-27T03:22:34.984124Z","iopub.execute_input":"2023-10-27T03:22:34.984538Z","iopub.status.idle":"2023-10-27T03:22:35.042780Z","shell.execute_reply.started":"2023-10-27T03:22:34.984496Z","shell.execute_reply":"2023-10-27T03:22:35.041518Z"},"trusted":true},"execution_count":76,"outputs":[{"name":"stdout","text":"{'input_ids': <tf.Tensor: shape=(64, 88), dtype=int64, numpy=\narray([[  0, 118, 619, ...,   1,   1,   1],\n       [  0, 118, 619, ...,   1,   1,   1],\n       [  0, 118, 619, ...,   1,   1,   1],\n       ...,\n       [  0, 118, 619, ...,   1,   1,   1],\n       [  0, 118,  33, ...,   1,   1,   1],\n       [  0, 757,  45, ...,   1,   1,   1]])>, 'attention_mask': <tf.Tensor: shape=(64, 88), dtype=int64, numpy=\narray([[1, 1, 1, ..., 0, 0, 0],\n       [1, 1, 1, ..., 0, 0, 0],\n       [1, 1, 1, ..., 0, 0, 0],\n       ...,\n       [1, 1, 1, ..., 0, 0, 0],\n       [1, 1, 1, ..., 0, 0, 0],\n       [1, 1, 1, ..., 0, 0, 0]])>} \n\n tf.Tensor(\n[1 1 0 1 1 1 0 0 1 2 1 4 0 1 1 0 3 1 1 1 0 0 1 0 1 1 0 0 0 1 3 5 4 1 4 0 1\n 0 0 0 1 4 1 0 1 1 1 0 0 1 1 4 1 3 3 1 0 1 0 0 0 0 1 4], shape=(64,), dtype=int64)\n","output_type":"stream"}]},{"cell_type":"code","source":"class ROBERTAForClassification(tf.keras.Model):\n    \n    def __init__(self, roberta_model, num_classes):\n        super().__init__()\n        self.bert = roberta_model\n        self.fc = tf.keras.layers.Dense(num_classes, activation='softmax')\n        \n    def call(self, inputs):\n        x = self.bert(inputs)[1]\n        return self.fc(x)","metadata":{"execution":{"iopub.status.busy":"2023-10-27T03:22:35.044084Z","iopub.execute_input":"2023-10-27T03:22:35.044405Z","iopub.status.idle":"2023-10-27T03:22:35.051709Z","shell.execute_reply.started":"2023-10-27T03:22:35.044376Z","shell.execute_reply":"2023-10-27T03:22:35.050597Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"classifier = ROBERTAForClassification(model, num_classes=6)\n\nclassifier.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n    metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-27T03:22:35.053277Z","iopub.execute_input":"2023-10-27T03:22:35.053748Z","iopub.status.idle":"2023-10-27T03:22:35.075172Z","shell.execute_reply.started":"2023-10-27T03:22:35.053704Z","shell.execute_reply":"2023-10-27T03:22:35.074115Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"history = classifier.fit(\n    train_dataset,\n    epochs=3\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-27T03:22:35.078548Z","iopub.execute_input":"2023-10-27T03:22:35.078878Z","iopub.status.idle":"2023-10-27T03:30:42.650888Z","shell.execute_reply.started":"2023-10-27T03:22:35.078850Z","shell.execute_reply":"2023-10-27T03:30:42.649843Z"},"trusted":true},"execution_count":79,"outputs":[{"name":"stdout","text":"Epoch 1/3\n250/250 [==============================] - 175s 626ms/step - loss: 0.7504 - accuracy: 0.7241\nEpoch 2/3\n250/250 [==============================] - 156s 625ms/step - loss: 0.2316 - accuracy: 0.9118\nEpoch 3/3\n250/250 [==============================] - 156s 625ms/step - loss: 0.1558 - accuracy: 0.9337\n","output_type":"stream"}]},{"cell_type":"code","source":"classifier.evaluate(test_dataset)","metadata":{"execution":{"iopub.status.busy":"2023-10-27T03:30:42.652152Z","iopub.execute_input":"2023-10-27T03:30:42.652468Z","iopub.status.idle":"2023-10-27T03:30:50.891664Z","shell.execute_reply.started":"2023-10-27T03:30:42.652439Z","shell.execute_reply":"2023-10-27T03:30:50.890695Z"},"trusted":true},"execution_count":80,"outputs":[{"name":"stdout","text":"32/32 [==============================] - 8s 159ms/step - loss: 0.1679 - accuracy: 0.9310\n","output_type":"stream"},{"execution_count":80,"output_type":"execute_result","data":{"text/plain":"[0.16786357760429382, 0.9309999942779541]"},"metadata":{}}]}]}